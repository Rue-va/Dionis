Assuming unrestricted shared filesystem usage.
host: DESKTOP-OB4VAQ4
Building DAG of jobs...
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                count
---------------  -------
all                    1
consume_kafka          1
generate_report        1
process_audio          1
scrape_species         1
total                  5

Select jobs to execute...
Execute 1 jobs...
[Tue Dec  2 15:36:24 2025]
localrule scrape_species:
    output: species.done
    jobid: 4
    reason: Missing output files: species.done; Code has changed since last execution
    resources: tmpdir=C:\Users\Korisnik\AppData\Local\Temp
[Tue Dec  2 15:36:25 2025]
Finished jobid: 4 (Rule: scrape_species)
1 of 5 steps (20%) done
Select jobs to execute...
Execute 1 jobs...
[Tue Dec  2 15:36:25 2025]
localrule consume_kafka:
    input: species.done
    output: kafka.done
    jobid: 3
    reason: Missing output files: kafka.done; Input files updated by another job: species.done
    resources: tmpdir=C:\Users\Korisnik\AppData\Local\Temp
RuleException:
CalledProcessError in file "C:\Users\Korisnik\OneDrive - A1 Telekom Austria AG\Desktop\dionis_pipeline\Snakefile", line 13:
Command 'py kafka_consume.py && echo done > kafka.done' returned non-zero exit status 3221225786.
[Tue Dec  2 15:42:57 2025]
Error in rule consume_kafka:
    message: None
    jobid: 3
    input: species.done
    output: kafka.done
    shell:
        py kafka_consume.py && echo done > kafka.done
        (command exited with non-zero exit code)
Terminating processes on user request, this might take some time.
Complete log(s): C:\Users\Korisnik\OneDrive - A1 Telekom Austria AG\Desktop\dionis_pipeline\.snakemake\log\2025-12-02T153624.415149.snakemake.log
WorkflowError:
At least one job did not complete successfully.
